{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/y0tish/Health-Insurance-Cross-Sell-Prediction/blob/main/health_insurance_cross_sell_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Health Insurance Cross Sell Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual.\n",
        "##### **Team Member 1 -** Yotish Lakhnpal\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The objective of this project was to help an insurance company predict whether their policyholders from the past year would be interested in vehicle insurance provided by the company. To achieve this, the project started with data cleaning and data wrangling, followed by exploratory data analysis (EDA) which included univariate, bivariate, and multivariate analysis to gain insights into the data.\n",
        "\n",
        "After the EDA, feature engineering was performed based on the findings from the analysis. Hypothesis testing was also conducted using techniques such as Ch2, ANOVA, and T-test to identify the best features for prediction. Outliers were removed using the IQR method, and the problem of an imbalanced dataset was addressed using the SMOTE technique.\n",
        "\n",
        "Several classification machine learning models were then trained on the preprocessed data, including Logistic Regression, Gaussian Naive Bayes, Decision Tree, Random Forest, Xtra Tree, Adaboost, and XGBoost. To evaluate the models, metrics such as precision, recall, and ROC AUC score were used.\n",
        "\n",
        "Based on the evaluation metrics, the Adaboost model was found to have the best performance with a highest ROC AUC score of 0.7934. This means that the Adaboost model is able to accurately predict whether a customer would be interested in vehicle insurance or not, based on the information provided about demographics, vehicles, and policy."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The problem is to build a predictive model to determine whether customers who were provided with Health Insurance by an insurance company in the past year are also likely to be interested in Vehicle Insurance provided by the same company. The model will be based on demographic data such as gender, age, and region code type, vehicle data such as vehicle age and damage, and policy data such as premium and sourcing channel. The aim of this model is to help the company plan its communication strategy and optimize its revenue by targeting those customers who are likely to be interested in Vehicle Insurance.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from scipy.stats import chi2_contingency\n",
        "from scipy.stats import f_oneway\n",
        "from scipy.stats import ttest_ind\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/Capstone 3/TRAIN-HEALTH INSURANCE CROSS SELL PREDICTION.csv')"
      ],
      "metadata": {
        "id": "PSqkcP9cQZ04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "dataset"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(f'No of Columns:- {dataset.columns.value_counts().sum()}')\n",
        "print(f'No of Rows:- {dataset.iloc[:].value_counts().sum()}')"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "dataset.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Dataset contains both categorical and numeric variables**\n",
        "* **We can see that there are no null values**"
      ],
      "metadata": {
        "id": "RoWLyCshjqKR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "len(dataset[dataset.duplicated()])"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **There is no duplicate rows**"
      ],
      "metadata": {
        "id": "kMEs7_6ykDb-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "dataset.isna().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **No Null Values**"
      ],
      "metadata": {
        "id": "PyVcfruSkKxH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "dataset.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "dataset.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **The Gender column has two unique values, with Male being the most common, appearing 206,089 times.**\n",
        "* **The Driving_License column is mostly composed of 1's (99.8%)**\n",
        "* **The Previously_Insured column has a mean of 0.46, indicating that less than half of the customers had previously purchased insurance.**\n",
        "* **The Vehicle_Age column has three unique values, with 1-2 Year being the most common, appearing 200,316 times.**\n",
        "* **The Vehicle_Damage column has two unique values, with Yes being the most common, appearing 192,413 times.**\n",
        "* **The Response column has a mean of 0.12, indicating that only a small fraction of customers responded positively to purchasing a new insurance policy.**"
      ],
      "metadata": {
        "id": "0RNIxBw1kVRX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **id: Unique identifier for each customer**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "* **Gender: Gender of the customer (Male/Female)**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "* **Age: Age of the customer in years**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "* **Driving_License: Whether the customer has a valid driving license or not (0 - No, 1 - Yes)**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "* **Region_Code: Unique code assigned to each region of the country where the customer resides**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "* **Previously_Insured: Whether the customer already has vehicle insurance or not (0 - No, 1 - Yes)**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "* **Vehicle_Age: Age of the customer's vehicle (0-1 Year, 1-2 Year, >2 Years)**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "* **Vehicle_Damage: Whether customer's vehicle was damaged in the past or not (Yes/No)**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "* **Annual_Premium: The amount customer needs to pay as premium in the year**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "* **Policy_Sales_Channel: Anonymized Code for the channel of outreaching to the customer ie. Different Agents, Over Mail, Over Phone, In Person, etc.**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "* **Vintage: Number of days customer has been associated with the company.**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "* **Response: Whether the customer responded positively to the insurance policy or not (0 - No, 1 - Yes)**"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "dataset.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "dataset.head(3)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping id column.\n",
        "dataset=dataset.drop('id',axis=1)"
      ],
      "metadata": {
        "id": "s0i0KKWuk07J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Our dataset is ready to use.**\n",
        "* **By seeing our description of our dataset seperating our numeric and categorical variable.**"
      ],
      "metadata": {
        "id": "PQ9vhjfunur7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#defining numerical feature\n",
        "numerical_feature=['Age','Region_Code','Annual_Premium','Policy_Sales_Channel','Vintage']"
      ],
      "metadata": {
        "id": "oJq1c_jTr0sE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining categorical feature\n",
        "categorical_feature=['Gender','Driving_License','Previously_Insured','Vehicle_Age','Vehicle_Damage','Response']"
      ],
      "metadata": {
        "id": "zHE4GSvqtmWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[numerical_feature]"
      ],
      "metadata": {
        "id": "fKQ7-iBhuPcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[categorical_feature]"
      ],
      "metadata": {
        "id": "E8O0ObiMuV8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1(Analyzing our Numeric Variables)"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "#set up subplots grid\n",
        "fig,axs = plt.subplots(nrows=5,ncols=2,figsize=(12,12))\n",
        "#Loop over numerical feature dataframe \n",
        "for i,col in enumerate(dataset[numerical_feature].columns):\n",
        "  #Determine the subplots index for this column\n",
        "  row_index= i%5\n",
        "  column_index=i//5\n",
        "  #create histogram and boxplot\n",
        "  sns.histplot(x=col,data=dataset[numerical_feature],ax=axs[row_index,column_index],kde=True,bins=30)\n",
        "  sns.boxplot(x=col,data=dataset,ax=axs[row_index,column_index+1],color='cyan')\n",
        "\n",
        "# Adjust the layout and show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Annual Premium have outliers.**\n",
        "* **Vintage column has a uniform distribution meaning customers in the dataset have been associated with the company for roughly the same amount of time on average.**\n",
        "* **Dataset contains customers which has age mostly between 20-30 years.**\n"
      ],
      "metadata": {
        "id": "8HsUlYLxrI1I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining Pairplot feature\n",
        "paiplot_feature=pd.concat([dataset[numerical_feature],dataset['Response']],axis=1)"
      ],
      "metadata": {
        "id": "rcEAenSLSs8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "sns.pairplot(data=paiplot_feature,hue='Response',diag_kind='kde')"
      ],
      "metadata": {
        "id": "AUC6XUab78Dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Count for taking a vehicle insurance for each category is less.**\n",
        "* **Middle age people are adopting vehicle Insurance**\n",
        "* **Young consumers are not adopting the vehicle insurance, these consumers have highest reponse of 0.**\n",
        "* **Specific region have highest number of consumers in which both types of consumer are present which are accepting and rejecting the vehicle insurance. Although the count of accepting the insurance is also very low.**\n",
        "* **Mostly count of accepting the vechicle insurance is low.** "
      ],
      "metadata": {
        "id": "tLaquny7zRSX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "sns.heatmap(dataset[numerical_feature].corr(),annot=True, cmap='coolwarm')"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Policy_sales_Chanel has collinearity with age.**\n",
        "* **Let's try to convert the Policy sales Channel to categorical column.**\n"
      ],
      "metadata": {
        "id": "ol_6_xLe-jkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Policy sales channel value counts\n",
        "dataset['Policy_Sales_Channel'].value_counts()"
      ],
      "metadata": {
        "id": "RZ6daYw6BJ7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's make 4 channels for policy sales channel.**\n",
        "* **(0-40)-Channel A**\n",
        "* **(40-80)-Channel B**\n",
        "* **(80-120)-Channel C**\n",
        "* **(120-160)Channel D**"
      ],
      "metadata": {
        "id": "_tHwU3vWDBBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to group policy sales channels into four channels\n",
        "def sales_channel_group(channel):\n",
        "    if channel >= 0 and channel < 40:\n",
        "        return 'Channel A'\n",
        "    elif channel >= 40 and channel < 80:\n",
        "        return 'Channel B'\n",
        "    elif channel >= 80 and channel < 120:\n",
        "        return 'Channel C'\n",
        "    elif channel >= 120 and channel <= 160:\n",
        "        return 'Channel D'"
      ],
      "metadata": {
        "id": "IFikYxvHDAiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the function to the 'Policy_Sales_Channel' column and create a new column\n",
        "dataset['Sales_Channel_Group'] = dataset['Policy_Sales_Channel'].apply(sales_channel_group)"
      ],
      "metadata": {
        "id": "FNtjw6EqF29G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#droping Policy_Sales_Channel\n",
        "datset=dataset.drop('Policy_Sales_Channel',axis=1)"
      ],
      "metadata": {
        "id": "CivUd7Bkqp2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing policy channel from numerical feature\n",
        "numerical_feature.remove('Policy_Sales_Channel')"
      ],
      "metadata": {
        "id": "DphgVHBUq2oW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding column to categorical feature\n",
        "categorical_feature.append('Sales_Channel_Group')"
      ],
      "metadata": {
        "id": "Pse2TfM6rL2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Value counts of sales channel group\n",
        "dataset['Sales_Channel_Group'].value_counts()"
      ],
      "metadata": {
        "id": "Du5nFxh6GSBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Channel B and C has low value counts let's collabrate these 2 channel in A only.**\n"
      ],
      "metadata": {
        "id": "skPc-_9DILJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_channel(channel):\n",
        "    if channel in ['Channel A', 'Channel B', 'Channel C']:\n",
        "        return 'Channel A'\n",
        "    else:\n",
        "        return 'Channel D'\n",
        "# Apply the function to the 'Policy_Sales_Channel' column and create a new column\n",
        "dataset['Sales_Channel_Group'] = dataset['Sales_Channel_Group'].apply(combine_channel)\n"
      ],
      "metadata": {
        "id": "JI2EOpaZJayn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=dataset.drop('Policy_Sales_Channel',axis=1)"
      ],
      "metadata": {
        "id": "9wc8rLK_aMtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#value count of new column\n",
        "dataset['Sales_Channel_Group'].value_counts()"
      ],
      "metadata": {
        "id": "bqqHkoomPF3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ploting a countplot sales channel group\n",
        "plt.figure(figsize=(15,8))\n",
        "sns.countplot(x=dataset['Sales_Channel_Group'])"
      ],
      "metadata": {
        "id": "_l7bErwLi2Md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a dictionary to map the response values to colors\n",
        "pal = {1:\"skyblue\", 0:\"magenta\"}\n",
        "\n",
        "# Set the plot style to \"darkgrid\" and the figure size to 15x8 inches\n",
        "sns.set(style=\"darkgrid\")\n",
        "plt.subplots(figsize = (15,8))\n",
        "\n",
        "# Create a count plot of the \"Sales_Channel_Group\" column, with the response values as the hue\n",
        "ax = sns.countplot(x = \"Sales_Channel_Group\", \n",
        "                   hue=\"Response\",\n",
        "                   data = dataset, \n",
        "                   linewidth=4, \n",
        "                   palette = pal\n",
        ")\n",
        "\n",
        "# Get the legend and set the title to \"Response\"\n",
        "leg = ax.get_legend()\n",
        "leg.set_title(\"Response\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0KbuXTtGRxWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Channels between 120-160(Channel D) has conviced more number customers to accept the vehicle insurance.**"
      ],
      "metadata": {
        "id": "o_g5T4_mUgUD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Categorical Columns**\n",
        "\n",
        "---\n",
        "#### Chart - 5\n",
        "* **Gender**\n"
      ],
      "metadata": {
        "id": "09Hg0qNETJgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Gender'].value_counts()"
      ],
      "metadata": {
        "id": "lY8zDawnkzN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# Set figure size\n",
        "plt.figure(figsize=(15,8))\n",
        "\n",
        "# Get labels and sizes for the pie chart\n",
        "labels = dataset['Gender'].value_counts(sort = True).index\n",
        "sizes = dataset['Gender'].value_counts(sort = True)\n",
        "\n",
        "# Set colors for the pie chart\n",
        "colors = [\"Blue\",\"Yellow\"]\n",
        "\n",
        "# Create and show the pie chart with percentage labels and a title\n",
        "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=0)\n",
        "plt.title('Percent of Gender in dataset',size = 10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "F38ayvbUhknj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a dictionary to map the response values to colors\n",
        "pal = {1:\"green\", 0:\"gray\"}\n",
        "\n",
        "# Set the plot style to \"darkgrid\" and the figure size to 15x8 inches\n",
        "sns.set(style=\"darkgrid\")\n",
        "plt.subplots(figsize = (15,8))\n",
        "\n",
        "# Create a count plot of the \"Gender\" column, with the response values as the hue\n",
        "ax = sns.countplot(x = \"Gender\", \n",
        "                   hue=\"Response\",\n",
        "                   data = dataset, \n",
        "                   linewidth=4, \n",
        "                   palette = pal\n",
        ")\n",
        "\n",
        "# Get the legend and set the title to \"Response\"\n",
        "leg = ax.get_legend()\n",
        "leg.set_title(\"Response\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gWNgTfvXjsU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Ratio of Male and Female are 50-50**\n",
        "* **Perctage of accepting the vehicle insurance for both male and female are somewhat of same.**"
      ],
      "metadata": {
        "id": "1Nm_iB10TioZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7\n",
        "\n",
        "---\n",
        "* **Driving_License**\n"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Driving_License'].value_counts()"
      ],
      "metadata": {
        "id": "Feoy_MYcBEYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "plt.figure(figsize=(15,8))\n",
        "sns.countplot(x=dataset['Driving_License'])"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "30isenfmlvJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a dictionary to map the response values to colors\n",
        "pal = {1:\"seagreen\", 0:\"gray\"}\n",
        "\n",
        "# Set the plot style to \"darkgrid\" and the figure size to 15x8 inches\n",
        "sns.set(style=\"darkgrid\")\n",
        "plt.subplots(figsize = (15,8))\n",
        "\n",
        "# Create a count plot of the \"Driving_License\" column, with the response values as the hue\n",
        "ax = sns.countplot(x = \"Driving_License\", \n",
        "                   hue=\"Response\",\n",
        "                   data = dataset, \n",
        "                   linewidth=4, \n",
        "                   palette = pal\n",
        ")\n",
        "\n",
        "# Get the legend and set the title to \"Response\"\n",
        "leg = ax.get_legend()\n",
        "leg.set_title(\"Response\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6t5Vo7QrheMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Mostly Customers have Driving License and few of them are adopting the insurance.**"
      ],
      "metadata": {
        "id": "uaz2bnmSVEC6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9\n",
        "\n",
        "---\n",
        "\n",
        "* **Previously_Insured**"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Previously_Insured'].value_counts()"
      ],
      "metadata": {
        "id": "btrH8NnvHAbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "plt.figure(figsize=(15,8))\n",
        "sns.countplot(x=dataset['Previously_Insured'])"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Both customers are present in dataset 1 representing customers which already have vehicle insurance and 0 representing customers which does not have insurance.**"
      ],
      "metadata": {
        "id": "ElJQvBxRocdX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "v-Zo6PPUoS8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a dictionary called 'pal' with keys 1 and 0, and values \"magenta\" and \"cyan\" respectively.\n",
        "pal = {1:\"magenta\", 0:\"cyan\"}\n",
        "\n",
        "# Set the plotting style to \"darkgrid\".\n",
        "sns.set(style=\"darkgrid\")\n",
        "\n",
        "# Create a new figure with a size of 15x8 inches.\n",
        "plt.subplots(figsize = (15,8))\n",
        "\n",
        "# Create a count plot using Seaborn with the x-axis as the \"Previously_Insured\" column of the 'dataset' data, \n",
        "ax = sns.countplot(x = \"Previously_Insured\", \n",
        "                   hue=\"Response\",\n",
        "                   data = dataset, \n",
        "                   linewidth=4, \n",
        "                   palette = pal\n",
        ")\n",
        "\n",
        "# Get the legend object from the plot.\n",
        "leg = ax.get_legend()\n",
        "\n",
        "# Set the title of the legend to \"Response\".\n",
        "leg.set_title(\"Response\")\n",
        "\n",
        "# Get the text objects in the legend and set them to \"No\" and \"Yes\" instead of \"0\" and \"1\".\n",
        "legs = leg.texts\n",
        "legs[0].set_text(\"No\")\n",
        "legs[1].set_text(\"Yes\")\n",
        "\n",
        "# Show the plot.\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bWkt1llKklAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Mostly the insurance is adopted by those cutomers which have no insurance previously.**"
      ],
      "metadata": {
        "id": "bIgJ6KYvpHR5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11\n",
        "\n",
        "---\n",
        "* **Vehicle_Age**\n"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Vehicle_Age'].value_counts()"
      ],
      "metadata": {
        "id": "hIMGzDcJHHBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "plt.figure(figsize=(15,8))\n",
        "sns.countplot(x=dataset['Vehicle_Age'])"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Mostly the vehicles are new or age between 1-2 years.**"
      ],
      "metadata": {
        "id": "GtEwerwAqCY7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "DDqAV1k1uq3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a dictionary called 'pal' with keys 1 and 0, and values \"orange\" and \"red\" respectively.\n",
        "pal = {1:\"orange\", 0:\"red\"}\n",
        "\n",
        "# Set the plotting style to \"darkgrid\".\n",
        "sns.set(style=\"darkgrid\")\n",
        "\n",
        "# Create a new figure with a size of 15x8 inches.\n",
        "plt.subplots(figsize = (15,8))\n",
        "\n",
        "# Create a count plot using Seaborn with the x-axis as the \"Vehicle_Age\" column of the 'dataset' data, \n",
        "ax = sns.countplot(x = \"Vehicle_Age\", \n",
        "                   hue=\"Response\",\n",
        "                   data = dataset, \n",
        "                   linewidth=4, \n",
        "                   palette = pal\n",
        ")\n",
        "\n",
        "# Get the legend object from the plot.\n",
        "leg = ax.get_legend()\n",
        "\n",
        "# Set the title of the legend to \"Response\".\n",
        "leg.set_title(\"Response\")\n",
        "\n",
        "# Show the plot.\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oWZK6lAGl5LI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Insurance has taken by all type of vehicle age, But vehicle that has age between 1-2 years have taken most of the insurance.**\n",
        "* **Although the bar of not taking the insurance(Red Plot) is still high in this case also.**"
      ],
      "metadata": {
        "id": "326QwXqTuwKx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13\n",
        "\n",
        "---\n",
        "\n",
        "* **Vehicle_Damage**"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Vehicle_Damage'].value_counts()"
      ],
      "metadata": {
        "id": "t2ABDhEqHPQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "plt.figure(figsize=(15,8))\n",
        "sns.countplot(x=dataset['Vehicle_Damage'])"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Proportion of customers are equal for having a vehicle damage or not**"
      ],
      "metadata": {
        "id": "aijnu0bBiLo3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14"
      ],
      "metadata": {
        "id": "hjWca5GPhV4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a dictionary called 'pal' with keys 1 and 0, and values \"orange\" and \"black\" respectively.\n",
        "pal = {1:\"orange\", 0:\"black\"}\n",
        "\n",
        "# Set the plotting style to \"darkgrid\".\n",
        "sns.set(style=\"darkgrid\")\n",
        "\n",
        "# Create a new figure with a size of 15x8 inches.\n",
        "plt.subplots(figsize = (15,8))\n",
        "\n",
        "# Create a count plot using Seaborn with the x-axis as the \"Vehicle_Damage\" column of the 'dataset' data, \n",
        "ax = sns.countplot(x = \"Vehicle_Damage\", \n",
        "                   hue=\"Response\",\n",
        "                   data = dataset, \n",
        "                   linewidth=4, \n",
        "                   palette = pal\n",
        ")\n",
        "\n",
        "# Get the legend object from the plot.\n",
        "leg = ax.get_legend()\n",
        "\n",
        "# Set the title of the legend to \"Response\".\n",
        "leg.set_title(\"Response\")\n",
        "\n",
        "# Show the plot.\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YTn1UrwymNV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **We can clearly see that customers which have already damaged their vehcile are more likely to adopt the vehicle insurance.**"
      ],
      "metadata": {
        "id": "Kj5_7fliimQb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15\n",
        "\n",
        "---\n",
        "* **Response(Target Variable)**\n"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Response'].value_counts()"
      ],
      "metadata": {
        "id": "RDK-QnFJHaPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "plt.figure(figsize=(15,8))\n",
        "sns.countplot(x=dataset['Response'])"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **We Can see Very less customers in our dataset are adopting the vehicle insurance.**\n",
        "* **Results also inducates an imbalance dataset.**\n",
        "* **We have to use some Oversampling technique to deal with Imbalance dataset.**"
      ],
      "metadata": {
        "id": "fqhysUqxjHAm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 16"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "#set up subplots grid\n",
        "fig,axs = plt.subplots(nrows=2,ncols=2,figsize=(12,12))\n",
        "#Loop over numerical feature dataframe and create a \n",
        "for i,col in enumerate(dataset[numerical_feature].columns):\n",
        "  #Determine the subplots index for this column\n",
        "  row_index= i%2\n",
        "  column_index=i//2\n",
        "  # Create a strip plot for the current variable using Seaborn\n",
        "  sns.stripplot(x='Gender',y=col, hue='Response', data=dataset, palette='rocket', ax=axs[row_index, column_index])\n",
        "# Adjust the layout and show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Proportion of male and female are same .**\n",
        "* **Dataset contain customers which are present between 20-85 for both male and female.**\n",
        "* **In both categories there are customers which are paying high and low annual premium.**\n",
        "* **Females are willing to pay high annual premium for vehicle insurance.**"
      ],
      "metadata": {
        "id": "NB-JYU35QEGZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 17"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 17 visualization code\n",
        "#set up subplots grid\n",
        "fig,axs = plt.subplots(nrows=2,ncols=2,figsize=(12,12))\n",
        "#Loop over numerical feature dataframe and create a \n",
        "for i,col in enumerate(dataset[numerical_feature].columns):\n",
        "  #Determine the subplots index for this column\n",
        "  row_index= i%2\n",
        "  column_index=i//2\n",
        "  # Create a strip plot for the current variable using Seaborn\n",
        "  sns.stripplot(x='Driving_License',y=col, hue='Response', data=dataset, palette='muted', ax=axs[row_index, column_index])\n",
        "# Adjust the layout and show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Mostly Young customers does not have driving License and they are too in some regions in which company is targeting.**\n",
        "* **Some Customers which does not have driving license are accepting the vehicle insurance but at low annual premium.** "
      ],
      "metadata": {
        "id": "jbdJj4Y5SdLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 18"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 18 visualization code\n",
        "#set up subplots grid\n",
        "fig,axs = plt.subplots(nrows=2,ncols=2,figsize=(12,12))\n",
        "#Loop over numerical feature dataframe and create a \n",
        "for i,col in enumerate(dataset[numerical_feature].columns):\n",
        "  #Determine the subplots index for this column\n",
        "  row_index= i%2\n",
        "  column_index=i//2\n",
        "  # Create a strip plot for the current variable using Seaborn\n",
        "  sns.stripplot(x='Previously_Insured',y=col, hue='Response', data=dataset, palette='husl', ax=axs[row_index, column_index])\n",
        "# Adjust the layout and show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Customers which have not vehicle insurance previously are adopting the insurance at high annual premium too, These are the customers which we have to target more.**"
      ],
      "metadata": {
        "id": "vHL7_-Uwf4mf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 19"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "#set up subplots grid\n",
        "fig,axs = plt.subplots(nrows=2,ncols=2,figsize=(12,12))\n",
        "#Loop over numerical feature dataframe and create a \n",
        "for i,col in enumerate(dataset[numerical_feature].columns):\n",
        "  #Determine the subplots index for this column\n",
        "  row_index= i%2\n",
        "  column_index=i//2\n",
        "  # Create a strip plot for the current variable using Seaborn\n",
        "  sns.stripplot(x='Vehicle_Age',y=col, hue='Response', data=dataset, palette='Pastel1', ax=axs[row_index, column_index])\n",
        "# Adjust the layout and show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Customers which has new vehicle are willing pay high annual premium for vehicle insurance.**"
      ],
      "metadata": {
        "id": "6ENqRr0rhjkk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 20"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "#set up subplots grid\n",
        "fig,axs = plt.subplots(nrows=2,ncols=2,figsize=(12,12))\n",
        "#Loop over numerical feature dataframe and create a \n",
        "for i,col in enumerate(dataset[numerical_feature].columns):\n",
        "  #Determine the subplots index for this column\n",
        "  row_index= i%2\n",
        "  column_index=i//2\n",
        "  # Create a strip plot for the current variable using Seaborn\n",
        "  sns.stripplot(x='Vehicle_Damage',y=col, hue='Response', data=dataset, palette='Pastel2', ax=axs[row_index, column_index])\n",
        "# Adjust the layout and show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **In this case too customers whose vehicle was damaged earlier are more likely to adopt the insurance and adopting the insurance at high annual premium too.**\n",
        "\n",
        "---\n",
        "\n",
        "* **We can see in most of the cases annual premium have some relation with all categorical variables in some way**\n",
        "* **Proportion of male and female are same**\n",
        "* **We did not see any strong patterns of vintage column with categorical or numerical feature**"
      ],
      "metadata": {
        "id": "XibVCM-4gk2F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Feature Selection through Hypothesis Testing.**\n",
        "* **Taking significance value(p-value)=0.05 or confidence interval to be 95%**"
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###a) For Categorical Variables\n",
        "* **For all categorical variables i am using Chi2 method to see whether my categorical variables have significant relationship with my target variable.**\n",
        "* **Using ch2 becuase this method used to find correlation between two categorical variables.**"
      ],
      "metadata": {
        "id": "4g7JcLfxrTh5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Stating my research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis: There is no significant relationship between having a Gender and the adopting vechicle insurance.\n",
        "\n",
        "Alternative hypothesis: There is a significant relationship between having a Gender and adopting vechicle insurance."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Create the contingency table using pd.crosstab\n",
        "contingency_table1 = pd.crosstab(dataset['Gender'],dataset['Response'])"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contingency_table1"
      ],
      "metadata": {
        "id": "qC-3najNtCII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the chi-squared test\n",
        "stat, p, dof, _ = chi2_contingency(contingency_table1)\n",
        "print(f'Chi2_statstics : {stat}')\n",
        "print(f'p-value: {p}')\n",
        "if p>0.05:\n",
        "  print('There is no significant relationship between having a Gender and the adopting vechicle insurance')\n",
        "else:\n",
        "  print('There is a significant relationship between having a Gender and adopting vechicle insurance')  "
      ],
      "metadata": {
        "id": "sUFUpiyDtHSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Stating my research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis: There is no significant relationship between having a Driving_License and the adopting vechicle insurance.\n",
        "\n",
        "Alternative hypothesis: There is a significant relationship between having a Driving_License and adopting vechicle insurance."
      ],
      "metadata": {
        "id": "NpEzYUF1yHGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Create the contingency table using pd.crosstab\n",
        "contingency_table2 = pd.crosstab(dataset['Driving_License'],dataset['Response'])"
      ],
      "metadata": {
        "id": "qkqTUw7_yQSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contingency_table2"
      ],
      "metadata": {
        "id": "twFS32xWyXTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the chi-squared test\n",
        "stat, p, dof, _ = chi2_contingency(contingency_table2)\n",
        "print(f'Chi2_statstics : {stat}')\n",
        "print(f'p-value: {p}')\n",
        "if p>0.05:\n",
        "  print('There is no significant relationship between having a Driving_License and the adopting vechicle insurance')\n",
        "else:\n",
        "  print('There is a significant relationship between having a Driving_License and adopting vechicle insurance') "
      ],
      "metadata": {
        "id": "-1dvvMDsyf3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "StTMQNJVyqWS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Stating my research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "DikLbZYGywCe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis: There is no significant relationship between having a Previously_Insured and the adopting vechicle insurance.\n",
        "\n",
        "Alternative hypothesis: There is a significant relationship between having a Previously_Insured and adopting vechicle insurance."
      ],
      "metadata": {
        "id": "wlSrFAHmy2Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Create the contingency table using pd.crosstab\n",
        "contingency_table3 = pd.crosstab(dataset['Previously_Insured'],dataset['Response'])"
      ],
      "metadata": {
        "id": "6tk2CCqNzCJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contingency_table3"
      ],
      "metadata": {
        "id": "TApcGsGYzHdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the chi-squared test\n",
        "stat, p, dof, _ = chi2_contingency(contingency_table3)\n",
        "print(f'Chi2_statstics : {stat}')\n",
        "print(f'p-value: {p}')\n",
        "if p>0.05:\n",
        "  print('There is no significant relationship between having a Previously_Insured and the adopting vechicle insurance')\n",
        "else:\n",
        "  print('There is a significant relationship between having a Previously_Insured and adopting vechicle insurance') "
      ],
      "metadata": {
        "id": "Fb7X64aFzMVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 4"
      ],
      "metadata": {
        "id": "xcAQjfL_zvpt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Stating my research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "GJxh-AU4z1dp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis: There is no significant relationship between having a Vehicle_Age and the adopting vechicle insurance.\n",
        "\n",
        "Alternative hypothesis: There is a significant relationship between having a Vehicle_Age and adopting vechicle insurance."
      ],
      "metadata": {
        "id": "ou7uQAdnz67b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Create the contingency table using pd.crosstab\n",
        "contingency_table4 = pd.crosstab(dataset['Vehicle_Age'],dataset['Response'])"
      ],
      "metadata": {
        "id": "U-R5Y0di0HhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contingency_table4"
      ],
      "metadata": {
        "id": "0SyLDeyH0LLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the chi-squared test\n",
        "stat, p, dof, _ = chi2_contingency(contingency_table4)\n",
        "print(f'Chi2_statstics : {stat}')\n",
        "print(f'p-value: {p}')\n",
        "if p>0.05:\n",
        "  print('There is no significant relationship between having a  Vehicle_Age and the adopting vechicle insurance')\n",
        "else:\n",
        "  print('There is a significant relationship between having a  Vehicle_Age and adopting vechicle insurance') "
      ],
      "metadata": {
        "id": "TJoXajLa0Nfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 5"
      ],
      "metadata": {
        "id": "SZAA5ZFn0h2L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Stating my research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "X3dMN4Vc0n-B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis: There is no significant relationship between having a Vehicle_Damage and the adopting vechicle insurance.\n",
        "\n",
        "Alternative hypothesis: There is a significant relationship between having a Vehicle_Damage and adopting vechicle insurance."
      ],
      "metadata": {
        "id": "ezra3tAE0rWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Create the contingency table using pd.crosstab\n",
        "contingency_table5 = pd.crosstab(dataset['Vehicle_Damage'],dataset['Response'])"
      ],
      "metadata": {
        "id": "LfvwKthp04PN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contingency_table5"
      ],
      "metadata": {
        "id": "sLSZu90N0-4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the chi-squared test\n",
        "stat, p, dof, _ = chi2_contingency(contingency_table5)\n",
        "print(f'Chi2_statstics : {stat}')\n",
        "print(f'p-value: {p}')\n",
        "if p>0.05:\n",
        "  print('There is no significant relationship between having a Vehicle_Damage and the adopting vechicle insurance')\n",
        "else:\n",
        "  print('There is a significant relationship between having a Vehicle_Damage and adopting vechicle insurance') "
      ],
      "metadata": {
        "id": "jXM5-_5b1Akn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 6"
      ],
      "metadata": {
        "id": "nWiuy5mO1NAj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Stating my research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "-14HNmnN1QwE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis: There is no significant relationship between having a Sales_Channel_Group and the adopting vechicle insurance.\n",
        "\n",
        "Alternative hypothesis: There is a significant relationship between having a Sales_Channel_Group and adopting vechicle insurance."
      ],
      "metadata": {
        "id": "_tlUV1rO1UZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Create the contingency table using pd.crosstab\n",
        "contingency_table6 = pd.crosstab(dataset['Sales_Channel_Group'],dataset['Response'])"
      ],
      "metadata": {
        "id": "boSJOSdT1gim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contingency_table6"
      ],
      "metadata": {
        "id": "DGm1S8vy1n_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the chi-squared test\n",
        "stat, p, dof, _ = chi2_contingency(contingency_table6)\n",
        "print(f'Chi2_statstics : {stat}')\n",
        "print(f'p-value: {p}')\n",
        "if p>0.05:\n",
        "  print('There is no significant relationship between having a Sales_Channel_Group and the adopting vechicle insurance')\n",
        "else:\n",
        "  print('There is a significant relationship between having a Sales_Channel_Group and adopting vechicle insurance') "
      ],
      "metadata": {
        "id": "_E_y83wA1p9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **We can clearly see that our all categorical variables have significant relationship with our target variable because all our hypothesis tests reject null hypothesis and accept alternate hypothesis.**\n",
        "* **Even our categorical column Sales_Channel_Group which we convert from numeric variable to categorical variable also shows significance with our target variable.** "
      ],
      "metadata": {
        "id": "cYgDWsVG2dVi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###b) For Numerical Variables.\n",
        "* **For all Numerical variables i am using Annova and T-Test method to see whether my numerical variables have significant difference in the mean values between the two groups defined by our target variable**\n",
        "* **Using Annova and T-test becuase this method used to find correlation between Numericalvariable and categorical variables.** "
      ],
      "metadata": {
        "id": "AUW5l-sv4A01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 7"
      ],
      "metadata": {
        "id": "xYdTzBQQ4tV1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Stating my research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "cXvYnJjR5_pZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis (H0): There is no significant difference in the mean values of the Age variable between the two groups defined by the \"Response\" variable.\n",
        "\n",
        "Alternative hypothesis (Ha): There is a significant difference in the mean values of the Age variable between the two groups defined by the \"Response\" variable."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into two groups based on binary target variable (response)\n",
        "group1 = dataset[dataset['Response']==0].loc[:,'Age']\n",
        "group2 = dataset[dataset['Response']==1].loc[:,'Age']"
      ],
      "metadata": {
        "id": "Kx8uxGUy4rsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Performing Annova statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        " # Perform ANOVA\n",
        "stat, p = f_oneway(group1, group2)\n",
        "print(f'ANOVA statstics : {stat}')\n",
        "print(f'p-value: {p}')\n",
        "\n",
        "# Interpret results\n",
        "if p > 0.05:\n",
        "    print(\"There is no significant difference in mean Age values between the groups.\")\n",
        "else:\n",
        "    print(\"There is a significant difference in mean Age values between the groups.\")"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement -8"
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Stating my research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "EnXoF5Eg_dGH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis (H0): There is no significant difference in the mean values of the Region_Code variable between the two groups defined by the \"Response\" variable.\n",
        "\n",
        "Alternative hypothesis (Ha): There is a significant difference in the mean values of the Region_Code variable between the two groups defined by the \"Response\" variable."
      ],
      "metadata": {
        "id": "WOe776W__oLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into two groups based on binary target variable (response)\n",
        "group1 = dataset[dataset['Response']==0].loc[:,'Region_Code']\n",
        "group2 = dataset[dataset['Response']==1].loc[:,'Region_Code']"
      ],
      "metadata": {
        "id": "Wh0Wgl7T_5VC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Performing T-Test statistical test."
      ],
      "metadata": {
        "id": "wZJhNeUfAA0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        " # Perform t-test\n",
        "stat, p = ttest_ind(group1, group2)\n",
        "print(f't-test statstics : {stat}')\n",
        "print(f'p-value: {p}')\n",
        "\n",
        "# Interpret results\n",
        "if p > 0.05:\n",
        "    print(\"There is no significant difference in mean Region_Code values between the groups.\")\n",
        "else:\n",
        "    print(\"There is a significant difference in mean Region_Code values between the groups.\")"
      ],
      "metadata": {
        "id": "621GGGfG_9O4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement -8"
      ],
      "metadata": {
        "id": "gpFrTjUCAqNd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Stating my research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "i8DQchFgAs-l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis (H0): There is no significant difference in the mean values of the Annual_Premium variable between the two groups defined by the \"Response\" variable.\n",
        "\n",
        "Alternative hypothesis (Ha): There is a significant difference in the mean values of the Annual_Premium variable between the two groups defined by the \"Response\" variable."
      ],
      "metadata": {
        "id": "UIl0mIf7Avs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into two groups based on binary target variable (response)\n",
        "group1 = dataset[dataset['Response']==0].loc[:,'Annual_Premium']\n",
        "group2 = dataset[dataset['Response']==1].loc[:,'Annual_Premium']"
      ],
      "metadata": {
        "id": "yeaM2TC2A4Zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing Annova statistical test."
      ],
      "metadata": {
        "id": "vs0sOOhPA_Pb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        " # Perform ANOVA\n",
        "stat, p = f_oneway(group1, group2)\n",
        "print(f'ANOVA statstics : {stat}')\n",
        "print(f'p-value: {p}')\n",
        "\n",
        "# Interpret results\n",
        "if p > 0.05:\n",
        "    print(\"There is no significant difference in mean Annual_Premium values between the groups.\")\n",
        "else:\n",
        "    print(\"There is a significant difference in mean Annual_Premium values between the groups.\")"
      ],
      "metadata": {
        "id": "s6NHrwxEBEV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hypothetical Statement -8"
      ],
      "metadata": {
        "id": "Jc5Ko5ouBTBX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Stating my research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "GG0inT3EBVps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis (H0): There is no significant difference in the mean values of the Vintage variable between the two groups defined by the \"Response\" variable.\n",
        "\n",
        "Alternative hypothesis (Ha): There is a significant difference in the mean values of the Vintage variable between the two groups defined by the \"Response\" variable."
      ],
      "metadata": {
        "id": "lEOs1A7oBZUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into two groups based on binary target variable (response)\n",
        "group1 = dataset[dataset['Response']==0].loc[:,'Vintage']\n",
        "group2 = dataset[dataset['Response']==1].loc[:,'Vintage']"
      ],
      "metadata": {
        "id": "1nCkFWb7Bioy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing Annova statistical test."
      ],
      "metadata": {
        "id": "5HysTUYnBot6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        " # Perform ANOVA\n",
        "stat, p = f_oneway(group1, group2)\n",
        "print(f'ANOVA statstics : {stat}')\n",
        "print(f'p-value: {p}')\n",
        "\n",
        "# Interpret results\n",
        "if p > 0.05:\n",
        "    print(\"There is no significant difference in mean Vintage values between the groups.\")\n",
        "else:\n",
        "    print(\"There is a significant difference in mean Vintage values between the groups.\")"
      ],
      "metadata": {
        "id": "xm0_gO_cB1ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **The results shows that our all numerical variable have significant difference in the mean values between the two groups defined by our target variable except Vintage column.**\n",
        "* **Dropping the Vintage column from our analysis might be a reasonable approach.**"
      ],
      "metadata": {
        "id": "_chV9UVfCLSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Droping the vintage column\n",
        "dataset=dataset.drop('Vintage',axis=1)"
      ],
      "metadata": {
        "id": "c6PHz_UbSwXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adjusting our numerical feature\n",
        "numerical_feature.remove('Vintage')"
      ],
      "metadata": {
        "id": "qxGGXFefFQ1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "# Replace outliers in Annual_Premium column\n",
        "q1_premium = dataset['Annual_Premium'].quantile(0.25)\n",
        "q3_premium = dataset['Annual_Premium'].quantile(0.75)\n",
        "iqr_premium = q3_premium - q1_premium\n",
        "upper_bound_premium = q3_premium + 1.5*iqr_premium\n",
        "lower_bound_premium = q1_premium - 1.5*iqr_premium"
      ],
      "metadata": {
        "id": "aF2j_79G1kVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list\n",
        "lst=[]\n",
        "\n",
        "# Iterate through the values in the 'Annual_Premium' column of the dataset\n",
        "for i in dataset['Annual_Premium'].tolist():\n",
        "  \n",
        "  # If the value is greater than the upper bound for Annual_Premium, set it to the upper bound and append it to the list\n",
        "  if i > upper_bound_premium:\n",
        "    i = upper_bound_premium\n",
        "    lst.append(i)\n",
        "    \n",
        "  # If the value is less than the lower bound for Annual_Premium, set it to the lower bound and append it to the list\n",
        "  elif i < lower_bound_premium:\n",
        "    i = lower_bound_premium\n",
        "    lst.append(i)\n",
        "    \n",
        "  # Otherwise, append the original value to the list\n",
        "  else:\n",
        "    lst.append(i)\n"
      ],
      "metadata": {
        "id": "oFsmtexN6Tdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Treating annual premium\n",
        "dataset['Annual_Premium']=lst"
      ],
      "metadata": {
        "id": "i65l-gH2Odpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting boxplot of treated annual premium\n",
        "sns.boxplot(x=dataset['Annual_Premium'])"
      ],
      "metadata": {
        "id": "J0VG3xmPOpao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "# apply one-hot encoding on the gender column\n",
        "gender_dummies = pd.get_dummies(dataset['Gender'], prefix='gender')\n",
        "\n",
        "# concatenate the one-hot encoded variables with the original dataframe\n",
        "dataset = pd.concat([dataset, gender_dummies], axis=1)\n",
        "\n",
        "# drop the original gender column\n",
        "dataset.drop(['Gender'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Updating Categorical feature\n",
        "categorical_feature.remove('Gender')\n",
        "categorical_feature.append('gender_Female')\n",
        "categorical_feature.append('gender_Male')"
      ],
      "metadata": {
        "id": "Tsol7JA9HV-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply one-hot encoding on the Vehicle_Age column\n",
        "dataset['Vehicle_Age']=dataset['Vehicle_Age'].apply(lambda x: 1 if x == '< 1 Year' else 2 if x == '1-2 Year' else 3)\n"
      ],
      "metadata": {
        "id": "RSKZV-jnmqcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply one-hot encoding on the Vehicle_Damage column\n",
        "dataset['Vehicle_Damage'] = dataset['Vehicle_Damage'].apply(lambda x: 0 if x == 'No' else 1)\n"
      ],
      "metadata": {
        "id": "Z_8buG3ZnOf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## apply one-hot encoding on the Sales_Channel_Group column\n",
        "dataset['Sales_Channel_Group']=dataset['Sales_Channel_Group'].apply(lambda x: 1 if x == 'Channel A' else 2)"
      ],
      "metadata": {
        "id": "pEkb-BG6Xhj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "u-DOcP_enJx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#making corelation table for numerical feature\n",
        "dataset[numerical_feature].corr()"
      ],
      "metadata": {
        "id": "7BmtBFIvFmIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ploting corelation heatmap for numerical feature\n",
        "plt.figure(figsize=(15,8))\n",
        "sns.heatmap(abs(dataset[numerical_feature].corr()),annot=True)"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Based on this correlation matrix alone, we can conclude that the variables are weakly correlated and that there is no strong relationship between Age, Region_Code, and Annual_Premium.**"
      ],
      "metadata": {
        "id": "CPAONGHT_LZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#making corelation table for categorical feature\n",
        "dataset[categorical_feature].corr()"
      ],
      "metadata": {
        "id": "1u060mzDI-7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[categorical_feature]"
      ],
      "metadata": {
        "id": "cO1bKsv_k5vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Ploting corelation heatmap for categorical feature\n",
        "plt.figure(figsize=(15,8))\n",
        "sns.heatmap(abs(dataset[categorical_feature].corr()),annot=True,cmap='coolwarm')"
      ],
      "metadata": {
        "id": "fz-S5g_kGT3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_cat=dataset[categorical_feature]"
      ],
      "metadata": {
        "id": "Dd9ov3S0mlkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lets check vif scores\n",
        "def calc_vif(x):\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"variables\"] = x.columns\n",
        "    vif[\"VIF\"] = [variance_inflation_factor(x.values, i) for i in range(x.shape[1])]\n",
        "    return(vif)"
      ],
      "metadata": {
        "id": "rQWaEEf4a8yB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ignore_features = ['gender_Female','gender_Male','Driving_License']\n",
        "dataset_cat= dataset_cat[[col for col in  dataset_cat.columns if col not in ignore_features]]\n",
        "calc_vif(dataset_cat)"
      ],
      "metadata": {
        "id": "HVfH0OJQboGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=dataset.drop(['gender_Female','gender_Male','Driving_License'],axis=1)"
      ],
      "metadata": {
        "id": "NerbYF_Em8_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "id": "3e-e5b-ingEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.columns"
      ],
      "metadata": {
        "id": "h0MOZDfSnjSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=dataset.drop('Response',axis=1)\n",
        "y=dataset['Response']"
      ],
      "metadata": {
        "id": "CwmbMHduqeNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "oYvKpJaaFwcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "ALO6iDMuFmu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X is the feature matrix and y is the target variable\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "yxb5h9-LtOS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "# Instantiate the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform the training data\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "\n",
        "# Transform the test data using the fitted scaler\n",
        "x_test = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Response'].value_counts()"
      ],
      "metadata": {
        "id": "hngg7lyAAUys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **We can clearly see that category 1(adopting insurance) is much less compared to category 0(Not adopting insurance), therefore our dataset is imbalance.** "
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)\n",
        "# Instantiate the SMOTE object\n",
        "smote = SMOTE()\n",
        "\n",
        "# Apply SMOTE to the training data\n",
        "x_train_resampled, y_train_resampled = smote.fit_resample(x_train, y_train)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of upsampling the training data is to address the class imbalance issue, where the minority class has very few instances compared to the majority class. By upsampling, the minority class instances are artificially increased to balance the two classes. This helps the logistic regression model to learn from both classes and make better predictions on the test data."
      ],
      "metadata": {
        "id": "wEVAoLZzN0-F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "# Instantiate the logistic regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Train the model on the resampled training data\n",
        "model.fit(x_train_resampled, y_train_resampled)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Make predictions on the train data\n",
        "y_pred_train=model.predict(x_train)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Calculate accuracy\n",
        "accuracy_train=accuracy_score(y_train,y_pred_train)\n",
        "accuracy_test = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy_train_data:\", accuracy_train)\n",
        "print(\"Accuracy_test_data:\", accuracy_test)\n",
        "\n",
        "# Calculate ROC AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "print(\"ROC AUC score:\", roc_auc)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm_lr = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm_lr)\n",
        "\n",
        "# Calculate classification report\n",
        "cr = classification_report(y_test, y_pred)\n",
        "print(\"Classification report:\")\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a no skill prediction (majority class)\n",
        "ns_probs = [0 for _ in range(len(y_test))]\n",
        "\n",
        "# predict probabilities for the test data using logistic regression model\n",
        "lr_probs = model.predict_proba(x_test)[:, 1]\n",
        "\n",
        "# calculate roc curves for the no skill model and the logistic regression model\n",
        "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
        "\n",
        "# plot the roc curve for the logistic regression model and the no skill model\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "plt.plot(lr_fpr, lr_tpr, marker='.', label='Logistic Regression')\n",
        "\n",
        "# set the x and y axis labels and title of the plot\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('AUC = %.2f' % auc(lr_fpr, lr_tpr))\n",
        "\n",
        "# display the legend and show the plot\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aIz4uZ_vA-jB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "param_grid={'C':[0.1,5,10]}\n",
        "grid_model=GridSearchCV(model,param_grid,scoring='roc_auc',cv=5)            \n",
        "# Fit the Algorithm\n",
        "grid_logreg=grid_model.fit(x_train_resampled,y_train_resampled)\n",
        "# Make predictions on the test data\n",
        "y_pred = grid_logreg.predict(x_test)\n",
        "# Make predictions on the train data\n",
        "y_pred_train=grid_logreg.predict(x_train)"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the best score\n",
        "best_score = grid_logreg.best_score_\n",
        "print(f'best_score-{best_score}')"
      ],
      "metadata": {
        "id": "7DE6xubF1pUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Calculate accuracy\n",
        "accuracy_train=accuracy_score(y_train,y_pred_train)\n",
        "accuracy_test = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy_train_data:\", accuracy_train)\n",
        "print(\"Accuracy_test_data:\", accuracy_test)\n",
        "\n",
        "# Calculate ROC AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "print(\"ROC AUC score:\", roc_auc)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm_lr_cv = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm_lr_cv)\n",
        "\n",
        "# Calculate classification report\n",
        "cr = classification_report(y_test, y_pred)\n",
        "print(\"Classification report:\")\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "ZfiAkW32191k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a no skill prediction (majority class)\n",
        "ns_probs = [0 for _ in range(len(y_test))]\n",
        "\n",
        "# predict probabilities for the test data using logistic regression model\n",
        "lr_probs = grid_logreg.predict_proba(x_test)[:, 1]\n",
        "\n",
        "# calculate roc curves for the no skill model and the logistic regression model\n",
        "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
        "\n",
        "# plot the roc curve for the logistic regression model and the no skill model\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "plt.plot(lr_fpr, lr_tpr, marker='.', label='Logistic Regression')\n",
        "\n",
        "# set the x and y axis labels and title of the plot\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('AUC = %.2f' % auc(lr_fpr, lr_tpr))\n",
        "\n",
        "# display the legend and show the plot\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vdumVxZn92zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation\n",
        "# Instantiate the Gaussian Naive Bayes model\n",
        "model_2 = GaussianNB()\n",
        "# Train the model on the resampled training data\n",
        "model_2.fit(x_train_resampled, y_train_resampled)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model_2.predict(x_test)\n",
        "\n",
        "# Make predictions on the train data\n",
        "y_pred_train=model_2.predict(x_train)"
      ],
      "metadata": {
        "id": "YhfBtw0fOzE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Calculate accuracy\n",
        "accuracy_train=accuracy_score(y_train,y_pred_train)\n",
        "accuracy_test = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy_train_data:\", accuracy_train)\n",
        "print(\"Accuracy_test_data:\", accuracy_test)\n",
        "\n",
        "# Calculate ROC AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "print(\"ROC AUC score:\", roc_auc)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Calculate classification report\n",
        "cr = classification_report(y_test, y_pred)\n",
        "print(\"Classification report:\")\n",
        "print(cr)\n"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a no skill prediction (majority class)\n",
        "ns_probs = [0 for _ in range(len(y_test))]\n",
        "\n",
        "# predict probabilities for the test data using logistic regression model\n",
        "lr_probs = model_2.predict_proba(x_test)[:, 1]\n",
        "\n",
        "# calculate roc curves for the no skill model and the logistic regression model\n",
        "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
        "\n",
        "# plot the roc curve for the logistic regression model and the no skill model\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "plt.plot(lr_fpr, lr_tpr, marker='.', label='Naive Bayes')\n",
        "\n",
        "# set the x and y axis labels and title of the plot\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('AUC = %.2f' % auc(lr_fpr, lr_tpr))\n",
        "\n",
        "# display the legend and show the plot\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YDeEH7u7-1x7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "param_grid={'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]}\n",
        "grid_model2=GridSearchCV(model_2,param_grid,scoring='roc_auc',cv=5)\n",
        "# Fit the Algorithm\n",
        "grid_nb=grid_model2.fit(x_train_resampled,y_train_resampled)\n",
        "# Make predictions on the test data\n",
        "y_pred = grid_nb.predict(x_test)\n",
        "\n",
        "# Make predictions on the train data\n",
        "y_pred_train=grid_nb.predict(x_train)"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the best score\n",
        "best_score = grid_nb.best_score_\n",
        "print(f'best_score-{best_score}')"
      ],
      "metadata": {
        "id": "DUmJPtgrECBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Calculate accuracy\n",
        "accuracy_train=accuracy_score(y_train,y_pred_train)\n",
        "accuracy_test = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy_train_data:\", accuracy_train)\n",
        "print(\"Accuracy_test_data:\", accuracy_test)\n",
        "\n",
        "# Calculate ROC AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "print(\"ROC AUC score:\", roc_auc)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm_nb = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm_nb)\n",
        "\n",
        "# Calculate classification report\n",
        "cr = classification_report(y_test, y_pred)\n",
        "print(\"Classification report:\")\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "kZMNInFaCJ_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a no skill prediction (majority class)\n",
        "ns_probs = [0 for _ in range(len(y_test))]\n",
        "\n",
        "# predict probabilities for the test data using logistic regression model\n",
        "lr_probs = grid_nb.predict_proba(x_test)[:, 1]\n",
        "\n",
        "# calculate roc curves for the no skill model and the logistic regression model\n",
        "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
        "\n",
        "# plot the roc curve for the logistic regression model and the no skill model\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "plt.plot(lr_fpr, lr_tpr, marker='.', label='Naive Bayes')\n",
        "\n",
        "# set the x and y axis labels and title of the plot\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('AUC = %.2f' % auc(lr_fpr, lr_tpr))\n",
        "\n",
        "# display the legend and show the plot\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "udAKU7HOCVqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "# Instantiate the Decision Tree model\n",
        "model_3 = DecisionTreeClassifier(random_state=42)\n",
        "# Fit the Algorithm\n",
        "# Train the model on the resampled training data\n",
        "model_3.fit(x_train_resampled, y_train_resampled)\n",
        "# Predict on the model\n",
        "# Make predictions on the test data\n",
        "y_pred = model_3.predict(x_test)\n",
        "\n",
        "# Make predictions on the train data\n",
        "y_pred_train=model_3.predict(x_train)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_train=accuracy_score(y_train,y_pred_train)\n",
        "accuracy_test = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy_train_data:\", accuracy_train)\n",
        "print(\"Accuracy_test_data:\", accuracy_test)\n",
        "\n",
        "# Calculate ROC AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "print(\"ROC AUC score:\", roc_auc)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Calculate classification report\n",
        "cr = classification_report(y_test, y_pred)\n",
        "print(\"Classification report:\")\n",
        "print(cr)\n"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a no skill prediction (majority class)\n",
        "ns_probs = [0 for _ in range(len(y_test))]\n",
        "\n",
        "# predict probabilities for the test data using logistic regression model\n",
        "lr_probs = model_3.predict_proba(x_test)[:, 1]\n",
        "\n",
        "# calculate roc curves for the no skill model and the logistic regression model\n",
        "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
        "\n",
        "# plot the roc curve for the logistic regression model and the no skill model\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "plt.plot(lr_fpr, lr_tpr, marker='.', label='Decision Tree')\n",
        "\n",
        "# set the x and y axis labels and title of the plot\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('AUC = %.2f' % auc(lr_fpr, lr_tpr))\n",
        "\n",
        "# display the legend and show the plot\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Zh9zzxcD_Wyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "param_grid={'criterion':['gini', 'entropy', 'log_loss'],\n",
        "             'max_depth':[10,50,100,200]}\n",
        "grid_model3=GridSearchCV(model_3,param_grid,scoring='roc_auc',cv=5)\n",
        "# Fit the Algorithm\n",
        "grid_dt=grid_model3.fit(x_train_resampled,y_train_resampled)\n",
        "# Make predictions on the test data\n",
        "y_pred = grid_dt.predict(x_test)\n",
        "\n",
        "# Make predictions on the train data\n",
        "y_pred_train=grid_dt.predict(x_train)"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the best score\n",
        "best_score = grid_dt.best_score_\n",
        "print(f'best_score-{best_score}')"
      ],
      "metadata": {
        "id": "kfW8aaarD4zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Visualizing evaluation Metric Score chart\n",
        "# Calculate accuracy\n",
        "accuracy_train=accuracy_score(y_train,y_pred_train)\n",
        "accuracy_test = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy_train_data:\", accuracy_train)\n",
        "print(\"Accuracy_test_data:\", accuracy_test)\n",
        "\n",
        "# Calculate ROC AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "print(\"ROC AUC score:\", roc_auc)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm_dt = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm_dt)\n",
        "\n",
        "# Calculate classification report\n",
        "cr = classification_report(y_test, y_pred)\n",
        "print(\"Classification report:\")\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "3dvBC339EEna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a no skill prediction (majority class)\n",
        "ns_probs = [0 for _ in range(len(y_test))]\n",
        "\n",
        "# predict probabilities for the test data using logistic regression model\n",
        "lr_probs = grid_dt.predict_proba(x_test)[:, 1]\n",
        "\n",
        "# calculate roc curves for the no skill model and the logistic regression model\n",
        "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
        "\n",
        "# plot the roc curve for the logistic regression model and the no skill model\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "plt.plot(lr_fpr, lr_tpr, marker='.', label='Decision Tree')\n",
        "\n",
        "# set the x and y axis labels and title of the plot\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('AUC = %.2f' % auc(lr_fpr, lr_tpr))\n",
        "\n",
        "# display the legend and show the plot\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-q6vTxi0EHei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####ML Model-4"
      ],
      "metadata": {
        "id": "l7RKH9ygEO8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 4 Implementation\n",
        "# Instantiate the BaggingClassifier model\n",
        "model_4 = BaggingClassifier(base_estimator=model_3,random_state=42)\n",
        "# Fit the Algorithm\n",
        "# Train the model on the resampled training data\n",
        "model_4.fit(x_train_resampled, y_train_resampled)\n",
        "# Predict on the model\n",
        "# Make predictions on the test data\n",
        "y_pred = model_4.predict(x_test)\n",
        "\n",
        "# Make predictions on the train data\n",
        "y_pred_train=model_4.predict(x_train)"
      ],
      "metadata": {
        "id": "1m1_A5yWpCKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Calculate accuracy\n",
        "accuracy_train=accuracy_score(y_train,y_pred_train)\n",
        "accuracy_test = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy_train_data:\", accuracy_train)\n",
        "print(\"Accuracy_test_data:\", accuracy_test)\n",
        "\n",
        "# Calculate ROC AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "print(\"ROC AUC score:\", roc_auc)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Calculate classification report\n",
        "cr = classification_report(y_test, y_pred)\n",
        "print(\"Classification report:\")\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "zDP0sAqNpcnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a no skill prediction (majority class)\n",
        "ns_probs = [0 for _ in range(len(y_test))]\n",
        "\n",
        "# predict probabilities for the test data using logistic regression model\n",
        "lr_probs = model_4.predict_proba(x_test)[:, 1]\n",
        "\n",
        "# calculate roc curves for the no skill model and the logistic regression model\n",
        "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
        "\n",
        "# plot the roc curve for the logistic regression model and the no skill model\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "plt.plot(lr_fpr, lr_tpr, marker='.', label='Bagging Classifier')\n",
        "\n",
        "# set the x and y axis labels and title of the plot\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('AUC = %.2f' % auc(lr_fpr, lr_tpr))\n",
        "\n",
        "# display the legend and show the plot\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X0Jtkgtm_5zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "qeEnK72NIyVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'n_estimators': [10,20,30]}\n",
        "grid_model4=GridSearchCV(model_4,param_grid,scoring='roc_auc',cv=5)\n",
        "# Fit the Algorithm\n",
        "grid_bc=grid_model4.fit(x_train_resampled,y_train_resampled)\n",
        "# Make predictions on the test data\n",
        "y_pred = grid_bc.predict(x_test)\n",
        "\n",
        "# Make predictions on the train data\n",
        "y_pred_train=grid_bc.predict(x_train)"
      ],
      "metadata": {
        "id": "VsnwUqo9IyCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the best score\n",
        "best_score = grid_bc.best_score_\n",
        "print(f'best_score-{best_score}')"
      ],
      "metadata": {
        "id": "8EQHXJezLjTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Calculate accuracy\n",
        "accuracy_train=accuracy_score(y_train,y_pred_train)\n",
        "accuracy_test = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy_train_data:\", accuracy_train)\n",
        "print(\"Accuracy_test_data:\", accuracy_test)\n",
        "\n",
        "# Calculate ROC AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "print(\"ROC AUC score:\", roc_auc)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm_bc = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm_bc)\n",
        "\n",
        "# Calculate classification report\n",
        "cr = classification_report(y_test, y_pred)\n",
        "print(\"Classification report:\")\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "idcsEljDLrCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a no skill prediction (majority class)\n",
        "ns_probs = [0 for _ in range(len(y_test))]\n",
        "\n",
        "# predict probabilities for the test data using logistic regression model\n",
        "lr_probs = grid_bc.predict_proba(x_test)[:, 1]\n",
        "\n",
        "# calculate roc curves for the no skill model and the logistic regression model\n",
        "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
        "\n",
        "# plot the roc curve for the logistic regression model and the no skill model\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "plt.plot(lr_fpr, lr_tpr, marker='.', label='Decision Tree')\n",
        "\n",
        "# set the x and y axis labels and title of the plot\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('AUC = %.2f' % auc(lr_fpr, lr_tpr))\n",
        "\n",
        "# display the legend and show the plot\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bDTaXDAOLucT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####ML Model 5"
      ],
      "metadata": {
        "id": "EqhAQJjlPbX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 5 Implementation\n",
        "# Instantiate the RandomForestClassifier model\n",
        "model_5 = RandomForestClassifier(random_state=42)\n",
        "# Fit the Algorithm\n",
        "# Train the model on the resampled training data\n",
        "model_5.fit(x_train_resampled, y_train_resampled)\n",
        "# Predict on the model\n",
        "# Make predictions on the test data\n",
        "y_pred = model_5.predict(x_test)\n",
        "\n",
        "# Make predictions on the train data\n",
        "y_pred_train=model_5.predict(x_train)"
      ],
      "metadata": {
        "id": "oZmRI8TUpg7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Calculate accuracy\n",
        "accuracy_train=accuracy_score(y_train,y_pred_train)\n",
        "accuracy_test = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy_train_data:\", accuracy_train)\n",
        "print(\"Accuracy_test_data:\", accuracy_test)\n",
        "\n",
        "# Calculate ROC AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "print(\"ROC AUC score:\", roc_auc)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Calculate classification report\n",
        "cr = classification_report(y_test, y_pred)\n",
        "print(\"Classification report:\")\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "bq53ASq9p5iZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a no skill prediction (majority class)\n",
        "ns_probs = [0 for _ in range(len(y_test))]\n",
        "\n",
        "# predict probabilities for the test data using logistic regression model\n",
        "lr_probs = model_5.predict_proba(x_test)[:, 1]\n",
        "\n",
        "# calculate roc curves for the no skill model and the logistic regression model\n",
        "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
        "\n",
        "# plot the roc curve for the logistic regression model and the no skill model\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "plt.plot(lr_fpr, lr_tpr, marker='.', label='Random Forest')\n",
        "\n",
        "# set the x and y axis labels and title of the plot\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('AUC = %.2f' % auc(lr_fpr, lr_tpr))\n",
        "\n",
        "# display the legend and show the plot\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vm4cgKC_Al4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "JJbk6wWRPhZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'n_estimators': [10, 50], 'max_depth': [5, 10,20]}\n",
        "grid_model5=GridSearchCV(model_5,param_grid,scoring='roc_auc',cv=5)\n",
        "# Fit the Algorithm\n",
        "grid_rf=grid_model5.fit(x_train_resampled,y_train_resampled)\n",
        "# Make predictions on the test data\n",
        "y_pred = grid_rf.predict(x_test)\n",
        "# Make predictions on the train data\n",
        "y_pred_train=grid_rf.predict(x_train)"
      ],
      "metadata": {
        "id": "3hYK4bqqPm36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the best score\n",
        "best_score = grid_rf.best_score_\n",
        "print(f'best_score-{best_score}')"
      ],
      "metadata": {
        "id": "CKGSkNKWRB1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Calculate accuracy\n",
        "accuracy_train=accuracy_score(y_train,y_pred_train)\n",
        "accuracy_test = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy_train_data:\", accuracy_train)\n",
        "print(\"Accuracy_test_data:\", accuracy_test)\n",
        "\n",
        "# Calculate ROC AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "print(\"ROC AUC score:\", roc_auc)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm_rf = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm_rf)\n",
        "\n",
        "# Calculate classification report\n",
        "cr = classification_report(y_test, y_pred)\n",
        "print(\"Classification report:\")\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "cTFvhwCzRYd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a no skill prediction (majority class)\n",
        "ns_probs = [0 for _ in range(len(y_test))]\n",
        "\n",
        "# predict probabilities for the test data using logistic regression model\n",
        "lr_probs = grid_rf.predict_proba(x_test)[:, 1]\n",
        "\n",
        "# calculate roc curves for the no skill model and the logistic regression model\n",
        "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
        "\n",
        "# plot the roc curve for the logistic regression model and the no skill model\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "plt.plot(lr_fpr, lr_tpr, marker='.', label='Decision Tree')\n",
        "\n",
        "# set the x and y axis labels and title of the plot\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('AUC = %.2f' % auc(lr_fpr, lr_tpr))\n",
        "\n",
        "# display the legend and show the plot\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e9Vv3Av2RaIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####ML Model-6"
      ],
      "metadata": {
        "id": "A3ahgjnrRstM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 6 Implementation\n",
        "# Instantiate the ExtraTreesClassifier model\n",
        "model_6 = ExtraTreesClassifier( random_state=42)\n",
        "# Fit the Algorithm\n",
        "# Train the model on the resampled training data\n",
        "model_6.fit(x_train_resampled, y_train_resampled)\n",
        "# Predict on the model\n",
        "# Make predictions on the test data\n",
        "y_pred = model_6.predict(x_test)\n",
        "\n",
        "# Make predictions on the train data\n",
        "y_pred_train=model_6.predict(x_train)"
      ],
      "metadata": {
        "id": "AuSTzzytp-ZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Calculate accuracy\n",
        "accuracy_train=accuracy_score(y_train,y_pred_train)\n",
        "accuracy_test = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy_train_data:\", accuracy_train)\n",
        "print(\"Accuracy_test_data:\", accuracy_test)\n",
        "\n",
        "# Calculate ROC AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "print(\"ROC AUC score:\", roc_auc)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Calculate classification report\n",
        "cr = classification_report(y_test, y_pred)\n",
        "print(\"Classification report:\")\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "RaP74Tj2qPbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a no skill prediction (majority class)\n",
        "ns_probs = [0 for _ in range(len(y_test))]\n",
        "\n",
        "# predict probabilities for the test data using logistic regression model\n",
        "lr_probs = model_6.predict_proba(x_test)[:, 1]\n",
        "\n",
        "# calculate roc curves for the no skill model and the logistic regression model\n",
        "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
        "\n",
        "# plot the roc curve for the logistic regression model and the no skill model\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "plt.plot(lr_fpr, lr_tpr, marker='.', label=' ExtraTrees')\n",
        "\n",
        "# set the x and y axis labels and title of the plot\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('AUC = %.2f' % auc(lr_fpr, lr_tpr))\n",
        "\n",
        "# display the legend and show the plot\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zAENSJ4FAqwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "hInbe3z3RxMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'n_estimators': [10, 50], 'max_depth': [5, 10,20]}\n",
        "grid_model6=GridSearchCV(model_6,param_grid,scoring='roc_auc',cv=5)\n",
        "# Fit the Algorithm\n",
        "grid_xt=grid_model6.fit(x_train_resampled,y_train_resampled)\n",
        "# Make predictions on the test data\n",
        "y_pred = grid_xt.predict(x_test)\n",
        "\n",
        "# Make predictions on the train data\n",
        "y_pred_train=grid_xt.predict(x_train)"
      ],
      "metadata": {
        "id": "69eon4AJR2Zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the best score\n",
        "best_score = grid_xt.best_score_\n",
        "print(f'best_score-{best_score}')"
      ],
      "metadata": {
        "id": "kjwt7H7cSLJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Calculate accuracy\n",
        "accuracy_train=accuracy_score(y_train,y_pred_train)\n",
        "accuracy_test = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy_train_data:\", accuracy_train)\n",
        "print(\"Accuracy_test_data:\", accuracy_test)\n",
        "\n",
        "# Calculate ROC AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "print(\"ROC AUC score:\", roc_auc)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm_xt = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm_xt)\n",
        "\n",
        "# Calculate classification report\n",
        "cr = classification_report(y_test, y_pred)\n",
        "print(\"Classification report:\")\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "zp86bBNvSOkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a no skill prediction (majority class)\n",
        "ns_probs = [0 for _ in range(len(y_test))]\n",
        "\n",
        "# predict probabilities for the test data using logistic regression model\n",
        "lr_probs =grid_xt.predict_proba(x_test)[:, 1]\n",
        "\n",
        "# calculate roc curves for the no skill model and the logistic regression model\n",
        "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
        "\n",
        "# plot the roc curve for the logistic regression model and the no skill model\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "plt.plot(lr_fpr, lr_tpr, marker='.', label=' ExtraTrees')\n",
        "\n",
        "# set the x and y axis labels and title of the plot\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('AUC = %.2f' % auc(lr_fpr, lr_tpr))\n",
        "\n",
        "# display the legend and show the plot\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E4X97AIsSRN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####ML Model 7"
      ],
      "metadata": {
        "id": "QHu_uUeXSeTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 7 Implementation\n",
        "# Instantiate the AdaBoostClassifier model\n",
        "model_7 = AdaBoostClassifier(random_state=42)\n",
        "# Fit the Algorithm\n",
        "# Train the model on the resampled training data\n",
        "model_7.fit(x_train_resampled, y_train_resampled)\n",
        "# Predict on the model\n",
        "# Make predictions on the test data\n",
        "y_pred = model_7.predict(x_test)\n",
        "\n",
        "# Make predictions on the train data\n",
        "y_pred_train=model_7.predict(x_train)"
      ],
      "metadata": {
        "id": "EuxsTyD9qv6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Calculate accuracy\n",
        "accuracy_train=accuracy_score(y_train,y_pred_train)\n",
        "accuracy_test = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy_train_data:\", accuracy_train)\n",
        "print(\"Accuracy_test_data:\", accuracy_test)\n",
        "\n",
        "# Calculate ROC AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "print(\"ROC AUC score:\", roc_auc)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Calculate classification report\n",
        "cr = classification_report(y_test, y_pred)\n",
        "print(\"Classification report:\")\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "J17IuPhAq6_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a no skill prediction (majority class)\n",
        "ns_probs = [0 for _ in range(len(y_test))]\n",
        "\n",
        "# predict probabilities for the test data using logistic regression model\n",
        "lr_probs = model_7.predict_proba(x_test)[:, 1]\n",
        "\n",
        "# calculate roc curves for the no skill model and the logistic regression model\n",
        "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
        "\n",
        "# plot the roc curve for the logistic regression model and the no skill model\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "plt.plot(lr_fpr, lr_tpr, marker='.', label='AdaBoost')\n",
        "\n",
        "# set the x and y axis labels and title of the plot\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('AUC = %.2f' % auc(lr_fpr, lr_tpr))\n",
        "\n",
        "# display the legend and show the plot\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ec3A0GcLAshl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "85FnS_9-Sk_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid ={'n_estimators': [10, 50], 'learning_rate': [0.1, 0.5, 1.0]}\n",
        "grid_model7=GridSearchCV(model_7,param_grid,scoring='roc_auc',cv=5)\n",
        "# Fit the Algorithm\n",
        "grid_ab=grid_model7.fit(x_train_resampled,y_train_resampled)\n",
        "# Make predictions on the test data\n",
        "y_pred = grid_ab.predict(x_test)\n",
        "\n",
        "# Make predictions on the train data\n",
        "y_pred_train=grid_ab.predict(x_train)"
      ],
      "metadata": {
        "id": "CJF0gzGNSq8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the best score\n",
        "best_score = grid_ab.best_score_\n",
        "print(f'best_score-{best_score}')"
      ],
      "metadata": {
        "id": "D8Z7plULS678"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Calculate accuracy\n",
        "accuracy_train=accuracy_score(y_train,y_pred_train)\n",
        "accuracy_test = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy_train_data:\", accuracy_train)\n",
        "print(\"Accuracy_test_data:\", accuracy_test)\n",
        "\n",
        "# Calculate ROC AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "print(\"ROC AUC score:\", roc_auc)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm_ab = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm_ab)\n",
        "\n",
        "# Calculate classification report\n",
        "cr = classification_report(y_test, y_pred)\n",
        "print(\"Classification report:\")\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "-VqBKeAkTAJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a no skill prediction (majority class)\n",
        "ns_probs = [0 for _ in range(len(y_test))]\n",
        "\n",
        "# predict probabilities for the test data using logistic regression model\n",
        "lr_probs = grid_ab.predict_proba(x_test)[:, 1]\n",
        "\n",
        "# calculate roc curves for the no skill model and the logistic regression model\n",
        "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
        "\n",
        "# plot the roc curve for the logistic regression model and the no skill model\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "plt.plot(lr_fpr, lr_tpr, marker='.', label='AdaBoost')\n",
        "\n",
        "# set the x and y axis labels and title of the plot\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('AUC = %.2f' % auc(lr_fpr, lr_tpr))\n",
        "\n",
        "# display the legend and show the plot\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3hK7KLs9TDyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####ML Model-8"
      ],
      "metadata": {
        "id": "NXgQsTQITJ-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 8 Implementation\n",
        "# Instantiate the XGBClassifier model\n",
        "model_8 = xgb.XGBClassifier(random_state=42)\n",
        "# Fit the Algorithm\n",
        "# Train the model on the resampled training data\n",
        "model_8.fit(x_train_resampled, y_train_resampled)\n",
        "# Predict on the model\n",
        "# Make predictions on the test data\n",
        "y_pred = model_8.predict(x_test)\n",
        "\n",
        "# Make predictions on the train data\n",
        "y_pred_train=model_8.predict(x_train)"
      ],
      "metadata": {
        "id": "SDJQEOAarDtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Calculate accuracy\n",
        "accuracy_train=accuracy_score(y_train,y_pred_train)\n",
        "accuracy_test = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy_train_data:\", accuracy_train)\n",
        "print(\"Accuracy_test_data:\", accuracy_test)\n",
        "\n",
        "# Calculate ROC AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "print(\"ROC AUC score:\", roc_auc)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Calculate classification report\n",
        "cr = classification_report(y_test, y_pred)\n",
        "print(\"Classification report:\")\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "XnB8DY9orO52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a no skill prediction (majority class)\n",
        "ns_probs = [0 for _ in range(len(y_test))]\n",
        "\n",
        "# predict probabilities for the test data using logistic regression model\n",
        "lr_probs = model_8.predict_proba(x_test)[:, 1]\n",
        "\n",
        "# calculate roc curves for the no skill model and the logistic regression model\n",
        "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
        "\n",
        "# plot the roc curve for the logistic regression model and the no skill model\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "plt.plot(lr_fpr, lr_tpr, marker='.', label='XGBoost')\n",
        "\n",
        "# set the x and y axis labels and title of the plot\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('AUC = %.2f' % auc(lr_fpr, lr_tpr))\n",
        "\n",
        "# display the legend and show the plot\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JjpH1um-AuO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "6rZa_vVLTQC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid ={'n_estimators': [10, 50], 'learning_rate': [0.1, 0.5, 1.0]}\n",
        "grid_model8=GridSearchCV(model_8,param_grid,scoring='roc_auc',cv=5)\n",
        "# Fit the Algorithm\n",
        "grid_xg=grid_model8.fit(x_train_resampled,y_train_resampled)\n",
        "# Make predictions on the test data\n",
        "y_pred = grid_xg.predict(x_test)\n",
        "\n",
        "# Make predictions on the train data\n",
        "y_pred_train=grid_xg.predict(x_train)"
      ],
      "metadata": {
        "id": "q4G5QmpRTPYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the best score\n",
        "best_score = grid_xg.best_score_\n",
        "print(f'best_score-{best_score}')"
      ],
      "metadata": {
        "id": "2U6WOmT1Tw7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Calculate accuracy\n",
        "accuracy_train=accuracy_score(y_train,y_pred_train)\n",
        "accuracy_test = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy_train_data:\", accuracy_train)\n",
        "print(\"Accuracy_test_data:\", accuracy_test)\n",
        "\n",
        "# Calculate ROC AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "print(\"ROC AUC score:\", roc_auc)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm_xg = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm_xg)\n",
        "\n",
        "# Calculate classification report\n",
        "cr = classification_report(y_test, y_pred)\n",
        "print(\"Classification report:\")\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "6EX7n4EET5D0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a no skill prediction (majority class)\n",
        "ns_probs = [0 for _ in range(len(y_test))]\n",
        "\n",
        "# predict probabilities for the test data using logistic regression model\n",
        "lr_probs = grid_xg.predict_proba(x_test)[:, 1]\n",
        "\n",
        "# calculate roc curves for the no skill model and the logistic regression model\n",
        "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
        "\n",
        "# plot the roc curve for the logistic regression model and the no skill model\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "plt.plot(lr_fpr, lr_tpr, marker='.', label='XGBoost')\n",
        "\n",
        "# set the x and y axis labels and title of the plot\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('AUC = %.2f' % auc(lr_fpr, lr_tpr))\n",
        "\n",
        "# display the legend and show the plot\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XqrTFM-3T75q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Dataset is imbalance hence we can't evaluate our models on accuracy, therefore we are evaluating our model on the basis on ROC AUC Scores.**\n",
        "* **ROC AUC Scores are best for Adaboost model with highest score of 0.7934.**\n",
        "* **ROC score and AUC is looking good for logestic regression,Naive Bayes and for some ensemble Classifier too**\n",
        "* **Decision Tree are not performing well as compared to other models.**\n",
        "* **It's a Good decision to choose logestic regression or Gaussian Naive Bayes as our model because in that case false negative is lowest, we don't want to missclassify those customers which want to adopt the vehicle insurance although in this case it have a higher false positive rate. In other words, they may identify some negative cases as positive, which could result in unnecessary or incorrect actions.**"
      ],
      "metadata": {
        "id": "2VkO56QQ0Abi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Feature Importance for best models"
      ],
      "metadata": {
        "id": "ONmkublUAnlx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AdaBoost**"
      ],
      "metadata": {
        "id": "Cgh8H_Nuctyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importance=model_7.feature_importances_\n",
        "importance_dict={'Features':list(x.columns),\n",
        "                 'importance':importance}\n",
        "importancee_df=pd.DataFrame(importance_dict)                 "
      ],
      "metadata": {
        "id": "TEZcKt6h2iUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importancee_df"
      ],
      "metadata": {
        "id": "vOoNstuhHmgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the feature importances as a barplot\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.title(\"Feature importances\")\n",
        "sns.barplot(x='Features', y='importance', data=importancee_df)\n",
        "plt.xticks(range(len(importancee_df)), importancee_df['Features'], rotation=90)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "8BjRKLuyBusY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Age has impacted the most in predection in adaboost model.**\n",
        "* **Sales_Channel_group, Annual premium has impacted least in prediction**"
      ],
      "metadata": {
        "id": "XqTTVZH_JvmA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logestic Regression**"
      ],
      "metadata": {
        "id": "-0z7E_18cy1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the coefficients of the independent variables\n",
        "coefficients = model.coef_[0]\n",
        "\n",
        "# Take absolute values of coefficients\n",
        "abs_coefficients = np.abs(coefficients)\n",
        "\n",
        "# Create a dictionary of feature importance with variable names as keys and feature importance values as values\n",
        "feature_importance = dict(zip(x.columns, abs_coefficients))\n",
        "\n",
        "# Sort the feature importance dictionary by descending order of feature importance\n",
        "sorted_feature_importance = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Print the sorted feature importance\n",
        "print(sorted_feature_importance)\n",
        "\n",
        "# Visualize the sorted feature importance\n",
        "\n",
        "plt.barh(range(len(sorted_feature_importance)), [val[1] for val in sorted_feature_importance], align='center')\n",
        "plt.yticks(range(len(sorted_feature_importance)), [val[0] for val in sorted_feature_importance])\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-Qd1Bl_SaywD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Customer have previously insurance or not is the most important feature in Logestic Regression**"
      ],
      "metadata": {
        "id": "RKOZXefYc3LV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **The goal of the project was to predict whether customers who had health insurance with the client would also be interested in vehicle insurance.**\n",
        "* **Demographic, vehicle, and policy data were available for each customer in the dataset.**\n",
        "* **The data was cleaned and preprocessed, including feature engineering and outlier removal.**\n",
        "* **The dataset was imbalanced, so SMOTE was used to balance the classes.\n",
        "Several classification models were trained and evaluated, including logistic regression, Gaussian naive Bayes, decision tree, random forest, extra tree, AdaBoost, and XGBoost.**\n",
        "* **The evaluation metrics used were precision, recall, and ROC AUC.\n",
        "The AdaBoost model had the highest ROC AUC score of 0.7934.**\n",
        "* **However, we observed that the precision for category 1 was low, indicating that there is scope for improvement in the model's performance.**\n",
        "\n",
        "---\n",
        "**Scope of Improvment**\n",
        "* **If the precision for Category 1(Accepting insurance) is low, it means that the model is making a high number of false positive predictions for customers who are not interested in Vehicle Insurance but are being targeted by the company. This could result in the company wasting resources and money on marketing and communication strategies that are not effective, as these customers are not interested in purchasing the product.**\n",
        "\n",
        "* **Moreover, if the company continuously sends irrelevant messages to customers, it may lead to a negative customer experience and brand perception, which can have long-term consequences on the company's reputation and revenue.**\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Understanding how my project is useful to stakeholders**\n",
        "\n",
        "* **The stakeholders can use the model to predict which customers are more likely to be interested in vehicle insurance. This will help them target their marketing efforts more effectively and improve their conversion rates.**\n",
        "* **By targeting only those customers who are likely to be interested in vehicle insurance, the stakeholders can save on marketing costs and other related expenses.**\n",
        "* **With a better understanding of their customers' needs and preferences, the stakeholders can offer more relevant insurance products and services, leading to increased customer satisfaction and loyalty. This, in turn, can lead to higher revenue for the company.**"
      ],
      "metadata": {
        "id": "W2J9_-B0rMiM"
      }
    }
  ]
}